Time & Space Complexity

Introduction

When writing programs, it's important to understand how efficient they are in terms of time and space. Time complexity refers to how the runtime of a program increases with the size of the input, while space complexity refers to how much memory the program uses.

What is Time Complexity?

Time complexity measures how the execution time of an algorithm changes with the size of the input. For example, if you have an array of numbers and you want to find the largest number, the time it takes will depend on the number of elements in the array.

Constant Time Complexity

An algorithm has constant time complexity if its execution time doesn't change with the size of the input. For example:

java

public void printFirstElement(int[] array) {
    System.out.println(array[0]);
}

This always takes the same amount of time, regardless of how big the array is.

Big O Notation

Big O notation describes the upper limit of the time complexity. For example:

java

public void printAllElements(int[] array) {
    for (int i = 0; i < array.length; i++) {
        System.out.println(array[i]);
    }
}

This has a time complexity of O(n), where n is the number of elements in the array.

Big Omega & Theta Notation

    Big Omega (Ω) describes the best-case scenario.
    Theta (Θ) describes the average-case scenario.

For example, a linear search in an array has:

    Best case: Ω(1) (if the element is the first one)
    Average case: Θ(n)

Common Complexities

    O(1): Constant time
    O(log n): Logarithmic time
    O(n): Linear time
    O(n log n): Linearithmic time
    O(n^2): Quadratic time
    O(2^n): Exponential time

Space Complexity

Space complexity measures how much memory an algorithm needs. For example:

java

public void createArray(int n) {
    int[] array = new int[n];
}

This uses O(n) space because it creates an array of size n.

Simple Loop Analysis

For a simple loop:

java

public void simpleLoop(int n) {
    for (int i = 0; i < n; i++) {
        System.out.println(i);
    }
}

The time complexity is O(n).

Nested Loop 1 Analysis

For a nested loop:

java

public void nestedLoop1(int n) {
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            System.out.println(i + " " + j);
        }
    }
}

The time complexity is O(n^2).

Nested Loop 2 Analysis

For a different nested loop:

java

public void nestedLoop2(int n) {
    for (int i = 0; i < n; i++) {
        for (int j = i; j < n; j++) {
            System.out.println(i + " " + j);
        }
    }
}

The time complexity is O(n^2).

Nested Loop 3 Analysis video

Let's say we have a more complex nested loop (you can imagine watching a video explanation for visualization):

java

public void nestedLoop3(int n) {
    for (int i = 1; i < n; i *= 2) {
        for (int j = 0; j < n; j++) {
            System.out.println(i + " " + j);
        }
    }
}

The outer loop runs log(n) times because i doubles each time. The inner loop runs n times, so the time complexity is O(n log n).

Bubble Sort Analysis

Bubble Sort is a simple sorting algorithm:

java

public void bubbleSort(int[] array) {
    int n = array.length;
    for (int i = 0; i < n - 1; i++) {
        for (int j = 0; j < n - i - 1; j++) {
            if (array[j] > array[j + 1]) {
                int temp = array[j];
                array[j] = array[j + 1];
                array[j + 1] = temp;
            }
        }
    }
}

Time complexity: O(n^2).

Binary Search Analysis

Binary Search is efficient for searching in a sorted array:

java

public int binarySearch(int[] array, int target) {
    int left = 0, right = array.length - 1;
    while (left <= right) {
        int mid = left + (right - left) / 2;
        if (array[mid] == target) {
            return mid;
        }
        if (array[mid] < target) {
            left = mid + 1;
        } else {
            right = mid - 1;
        }
    }
    return -1; // Element not found
}

Time complexity: O(log n).

Recursive Complexity Analysis (Factorial)

Factorial calculation using recursion:

java

public int factorial(int n) {
    if (n <= 1) {
        return 1;
    }
    return n * factorial(n - 1);
}

Time complexity: O(n).

Sum of N numbers Analysis

Summing first n numbers:

java

public int sumOfN(int n) {
    return n * (n + 1) / 2;
}

Time complexity: O(1) because it uses a formula.

Fibonacci Analysis

Calculating Fibonacci numbers recursively:

java

public int fibonacci(int n) {
    if (n <= 1) {
        return n;
    }
    return fibonacci(n - 1) + fibonacci(n - 2);
}

Time complexity: O(2^n).

Merge Sort Analysis

Merge Sort is a divide-and-conquer sorting algorithm:

java

public void mergeSort(int[] array, int left, int right) {
    if (left < right) {
        int mid = (left + right) / 2;
        mergeSort(array, left, mid);
        mergeSort(array, mid + 1, right);
        merge(array, left, mid, right);
    }
}

private void merge(int[] array, int left, int mid, int right) {
    // Merging logic here
}

Time complexity: O(n log n).

Recurrence Relation - Merge Sort

The recurrence relation for Merge Sort is:
T(n)=2T(n/2)+O(n)T(n)=2T(n/2)+O(n)

Power Function I - Analysis

Simple power function:

java

public int power(int x, int n) {
    int result = 1;
    for (int i = 0; i < n; i++) {
        result *= x;
    }
    return result;
}

Time complexity: O(n).

Power Function II - Analysis

Recursive power function:

java

public int power(int x, int n) {
    if (n == 0) {
        return 1;
    }
    return x * power(x, n - 1);
}

Time complexity: O(n).

Power Function III - Analysis

Optimized power function using divide and conquer:

java

public int power(int x, int n) {
    if (n == 0) {
        return 1;
    }
    int half = power(x, n / 2);
    if (n % 2 == 0) {
        return half * half;
    } else {
        return half * half * x;
    }
}

Time complexity: O(log n).

How to approach Coding Questions?

    Understand the problem.
    Break it down into smaller parts.
    Write pseudocode.
    Convert pseudocode to code.
    Optimize and test.

Master's Theorem (Reading Material)

Master's Theorem helps solve recurrence relations of the form:
T(n)=aT(nb)+f(n)T(n)=aT(bn​)+f(n)